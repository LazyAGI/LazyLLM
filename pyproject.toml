[tool.poetry]
name = "lazyllm"
version = "0.2.3"
description = "A Low-code Development Tool For Building Multi-agent LLMs Applications."
authors = ["wangzhihong <wangzhihong@sensetime.com>"]
license = "Apache-2.0 license"
readme = "README.md"
include = [
    "lazyllm/pyproject.toml",
]

[tool.poetry.dependencies]
python = "^3.10"
appdirs = "*"
loralib = "*"
toml = "*"
fastapi = ">=0.111.0"
loguru = ">=0.7.2"
pydantic = ">=2.5.0"
requests = ">=2.32.2"
uvicorn = "<0.29.0"
cloudpickle = ">=3.0.0"
flake8 = ">=7.0.0"
gradio = ">=3.48.0"
gradio-client = ">=0.6.1"
protobuf = ">=3.20.1"
setuptools = "<70.0.0"
docstring-parser = "^0.16"
json5 = "^0.9.25"
tiktoken = "^0.7.0"
spacy = "^3.7.5"
chromadb = "^0.5.5"
bm25s = "^0.1.10"
pystemmer = "^2.2.0.1"
nltk = "^3.8.1"
jieba = ">=0.42.1"
pyjwt = ">=2.8.0"
llama-index-core = "^0.11.2"
llama-index-readers-file = "^0.2.0"
sentence-transformers = "^3.0.1"
sentencepiece = "^0.2.0"
modelscope = "^1.17.1"
redis = { version = ">=5.0.4", optional = true }
huggingface-hub = { version = ">=0.23.1", optional = true }
llama-index = { version = ">=0.10.25", optional = true }
pandas = { version = ">=2.2.2", optional = true }
rank-bm25 = { version = ">=0.2.2", optional = true }
redisvl = { version = ">=0.1.3", optional = true }
datasets = { version = ">=2.18.0", optional = true }
deepspeed = { version = ">=0.12.3", optional = true }
fire = { version = ">=0.6.0", optional = true }
numpy = { version = ">=1.26.4", optional = true }
peft = { version = ">=0.3.0", optional = true }
torch = { version = ">=2.1.2", optional = true }
transformers = { version = ">=4.41.1", optional = true }
collie-lm = { version = ">=1.0.7", optional = true }
faiss-cpu = { version = ">=1.8.0", optional = true }
google = { version = ">=3.0.0", optional = true }
llama-index-embeddings-huggingface = { version = ">=0.2.0", optional = true }
llama-index-storage-docstore-redis = { version = ">=0.1.2", optional = true }
llama-index-storage-index-store-redis = { version = ">=0.1.2", optional = true }
llama-index-storage-kvstore-redis = { version = ">=0.1.5", optional = true }
llama-index-vector-stores-redis = { version = ">=0.2.0", optional = true }
llama-index-retrievers-bm25 = { version = ">=0.1.3", optional = true }
scikit-learn = { version = ">=1.5.0", optional = true }
tensorboard = { version = ">=2.16.2", optional = true }
tensorboard-data-server = { version = ">=0.7.2", optional = true }
torchvision = { version = ">=0.16.2", optional = true }
vllm = {version = "==0.5.0", optional = true}
wandb = { version = ">=0.17.0", optional = true }
chattts = {version = "^0.1.1", optional = true}
funasr = {version = "^1.1.4", optional = true}
lmdeploy = {version = "^0.5.3", optional = true}
timm = {version = "^1.0.8", optional = true}
diffusers = {version = "^0.30.0", optional = true}
sortedcontainers = {version = "^2.4.0", optional = true}
flash-attn = {version = "^2.6.3", optional = true}
lightllm = {version = "^0.0.1", optional = true}
lazyllm-llamafactory = {version = "^0.8.3.dev0", optional = true}

[tool.poetry.extras]
standard = [
    "datasets",
    "deepspeed",
    "faiss-cpu",
    "fire",
    "google",
    "llama-index",
    "llama-index-embeddings-huggingface",
    "modelscope",
    "numpy",
    "pandas",
    "peft",
    "rank-bm25",
    "scikit-learn",
    "torch",
    "torchvision",
    "transformers",
    "vllm",
    "wandb",
    "chattts",
    "funasr",
    "lmdeploy",
    "timm",
    "diffusers",
    "lazyllm-llamafactory"
]
full = [
    "datasets",
    "deepspeed",
    "faiss-cpu",
    "fire",
    "google",
    "llama-index",
    "llama-index-embeddings-huggingface",
    "modelscope",
    "numpy",
    "pandas",
    "peft",
    "rank-bm25",
    "scikit-learn",
    "torch",
    "torchvision",
    "transformers",
    "vllm",
    "wandb",
    "chattts",
    "funasr",
    "lmdeploy",
    "timm",
    "diffusers",
    "redis",
    "huggingface-hub",
    "redisvl",
    "collie-lm",
    "llama-index-storage-docstore-redis",
    "llama-index-storage-index-store-redis",
    "llama-index-storage-kvstore-redis",
    "llama-index-vector-stores-redis",
    "llama-index-retrievers-bm25",
    "tensorboard",
    "tensorboard-data-server",
    "sortedcontainers",
    "flash-attn",
    "lazyllm-llamafactory",
    "lightllm"
]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
lazyllm = "lazyllm.cli.main:main"
